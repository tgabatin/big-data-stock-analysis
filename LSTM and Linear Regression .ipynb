{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9645c45c",
   "metadata": {},
   "source": [
    "## Linear Regression and LSTM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960b3db7",
   "metadata": {},
   "source": [
    "It is understood that there are a variety of models that can be used for economic forecasting; however, not all models are made for the same purpose. While thre may be a variety of algorithms that can be used to predict stock prices - not all of them may yield viable solutions, nor can they determine whether they are strong indicators of how the stock market can yield and perform. \n",
    "\n",
    "Two very popular methods of machine learning algorithms that are used are the Linear Regression Model and the LSTM (Long Short-Term Memory) model. \n",
    "\n",
    "Both technical and quantitative analysis use these models in determining value; however, not all of these attempts in understanding the fluctuating price within the stock market have been entirely viable or successfuly. \n",
    "\n",
    "To determine the value of these two models and their effects on the stock market, we will do an analysis on Linear Regression and LSTM models, with a Convolutional Neural Network as the main predictor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227aeb96",
   "metadata": {},
   "source": [
    "## First Analysis: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51317bed",
   "metadata": {},
   "source": [
    "The primary purpose of linear regression is to separate variables in order to determine a relationship between the two. In this first model, we will determine whether it will be possible to train and split the data in order to see whether we can accurately predict the stock market prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a06252c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done importing\n"
     ]
    }
   ],
   "source": [
    "# Import Statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "print(\"Done importing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19dcf837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load symbols_valid_meta to get reference Stocks and ETFs with full name\n",
    "# Change this to match your filepath name\n",
    "nomenclature = pd.read_csv('/Users/taylor/ICS-438/big-data-stock-analysis/Notebooks/Data/symbols_valid_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ebda194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When reading the .csv in pandas df, special characters are treated differently\n",
    "# Manually renamed the files so no files are run into\n",
    "nomenclature.at[162,'Symbol'] = 'AGM-A'\n",
    "nomenclature.at[1068,'Symbol'] = 'CARR#'\n",
    "nomenclature.at[7457,'Symbol'] = 'UTX#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5980f3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock file count:  5884\n",
      "Etf file count:  2165\n"
     ]
    }
   ],
   "source": [
    "# Import statement\n",
    "import pathlib\n",
    "\n",
    "# Iterate through the number of stocks\n",
    "stock_count, etf_count = 0, 0\n",
    "for path in pathlib.Path('/Users/taylor/ICS-438/big-data-stock-analysis/Notebooks/Data/stocks').iterdir():\n",
    "    if path.is_file():\n",
    "        stock_count += 1\n",
    "print(\"Stock file count: \", stock_count)\n",
    "\n",
    "# Iterate through the number of etfs\n",
    "for path in pathlib.Path('/Users/taylor/ICS-438/big-data-stock-analysis/Notebooks/Data/etfs').iterdir():\n",
    "    if path.is_file():\n",
    "        etf_count += 1\n",
    "print(\"Etf file count: \", etf_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aa9356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the files into one big list of dataframes and normalize dates according to pandas\n",
    "# Yahoo finance package dealt with pandas date normalization already\n",
    "\n",
    "\"\"\"\n",
    "Please note:\n",
    "In order to run this, it is important to change your $PATH to reflect where the actual files are downloaded\n",
    "\"\"\"\n",
    "\n",
    "stock_df_list = []\n",
    "etf_df_list = []\n",
    "\n",
    "for i in range(len(nomenclature)):\n",
    "    if nomenclature['ETF'][i] == 'Y':\n",
    "        etf_df_list.append(pd.read_csv('Notebooks/Data/stocks/' + nomenclature['Symbol'][i] +'.csv'))\n",
    "    else:\n",
    "        stock_df_list.append(pd.read_csv('Notebooks/Data/etfs/' + nomenclature['Symbol'][i] +'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1506e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Separate stocks into 3 types and drop stocks with a history < 3 years, 2018 and younger\n",
    "Type 1: Longer than 25 years\n",
    "Type 2: 25 Years and Younger\n",
    "Type 3: After 2009\n",
    "We will only be using type 3 stocks, since we do not want to deal with market crashes\n",
    "and any other event that will affect the volatility\n",
    "\"\"\"\n",
    "\n",
    "stocks_relevant = [s for s in stock_df_list if s['Date'][0] < '2018-01-01']\n",
    "stocks_type_3 = [s for s in stocks_relevant if s['Date'][0] > '2009-12-31']\n",
    "stocks_type_2 = [s for s in stocks_relevant if s['Date'][0] > '1994-12-31']\n",
    "stocks_type_1 = [s for s in stocks_relevant if s['Date'][0] < '1994-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "012c03f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Cleaning, preprocessing drop NaN rows and change date to days after first\n",
    "for i in range(len(stocks_type_3)): \n",
    "    stocks_type_3[i].dropna(axis=0, how='any', inplace=True)\n",
    "    stocks_type_3[i]['Date'] = pd.to_datetime(stocks_type_3[i]['Date'])\n",
    "    stocks_type_3[i]['Date'] = (stocks_type_3[i]['Date'] - stocks_type_3[i]['Date'].min())  / np.timedelta64(1,'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e5a4da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_reg_accuracy(list_stock_df):\n",
    "    lin_acc = []\n",
    "    for i in range(len(list_stock_df)):\n",
    "        temp = list_stock_df[i]\n",
    "        temp = (temp-temp.min())/(temp.max()-temp.min()) #Min-Max Scaling\n",
    "        X = temp.drop(['Open','High', 'Low','Close', 'Adj Close'], axis=1)\n",
    "        y = temp['Open']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
    "        regressor = LinearRegression()\n",
    "        regressor.fit(X_train, y_train)\n",
    "        lin_acc.append(regressor.score(X_test, y_test))\n",
    "    return lin_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74411116",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = lin_reg_accuracy(stocks_type_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86258b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = filter(lambda x: x > 0.85, accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71d6b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(list(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb725070",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage of stocks with an R^2 value of greater than 85% is', length / len(accuracies), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f93979",
   "metadata": {},
   "source": [
    "The above determines that the percentage of stocks with an R^2 value of greater than 50% is approximately 0.067. This means that linear regressions are not viable tools to successfully predicts a stocks value. The results determine that there is only a small percentage of stocks that follow clear correlated linear trend over time, as expected during a clear economic expansion. The years that we have also chosen determine that no clear events that determine volatility could have affected these prices. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06d4202",
   "metadata": {},
   "source": [
    "## Time Series Prediction of Apple Stock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94675afa",
   "metadata": {},
   "source": [
    "The first step to determining whether these deep learning models are unsuccessful is to apply the, to how they compare to each other. We will be doing this time series prediction on Apple stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f956ac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c26bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get AAPL stock into df and cut time to 2014 - 2020\n",
    "aapl = pd.read_csv('Notebooks/Data/stocks/' + 'AAPL' +'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f239090",
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl = aapl.loc[(aapl['Date'] >= '2012-01-01') & (aapl['Date'] <= '2020-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6940491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train test\n",
    "training_size = int(len(aapl)*0.80)\n",
    "data_len = len(aapl)\n",
    "\n",
    "train, test = aapl[0:training_size],aapl[training_size:data_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1617805a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size -->  1609\n",
      "total length of data -->  2012\n",
      "Train length -->  1609\n",
      "Test length -->  403\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Size --> \", training_size)\n",
    "print(\"total length of data --> \", data_len)\n",
    "print(\"Train length --> \", len(train))\n",
    "print(\"Test length --> \", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fedd4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinMax scale values\n",
    "train = train.loc[:, [\"Open\"]].values\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_scaled = scaler.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aef884",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_len = len(train_scaled)\n",
    "X_train, y_train = [], []\n",
    "timesteps = 40\n",
    "\n",
    "for i in range(timesteps, end_len):\n",
    "    X_train.append(train_scaled[i - timesteps:i, 0])\n",
    "    y_train.append(train_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3740bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to reshape our data as RNN needs 3 dimensions\n",
    "#the size of data we have, the number of steps and the number of features\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb92ec49",
   "metadata": {},
   "source": [
    "## A Recurrent Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473cdb49",
   "metadata": {},
   "source": [
    "This is the creation of the model and a specification of the parameters. We will determine the hyperbolic tangent as an activation function and dimensionality of output space to be a total of 50 units. The parameter values do not contain any specific special features, but are mostly based around their default values and values in our examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed4266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "\n",
    "regressor.add(SimpleRNN(units = 50, activation = \"tanh\", return_sequences = True, input_shape = (X_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(SimpleRNN(units = 50, activation = \"tanh\", return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(SimpleRNN(units = 50, activation = \"tanh\", return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(SimpleRNN(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f7d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.compile(optimizer= \"adam\", loss = \"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad230d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100 \n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7232fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note: Only run this once, it takes a long time to run within local machine.\n",
    "\"\"\"\n",
    "regressor.fit(X_train, y_train, epochs = epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aaf1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_price = test.loc[:, [\"Open\"]].values\n",
    "print(\"Real Price Shape --> \", real_price.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f7176",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_total = pd.concat((aapl[\"Open\"], test[\"Open\"]), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(test) - timesteps:].values.reshape(-1,1)\n",
    "inputs = scaler.transform(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963cad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "\n",
    "for i in range(timesteps, real_price.shape[0]+timesteps):\n",
    "    X_test.append(inputs[i-timesteps:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "print(\"X_test shape --> \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9068a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "predict = regressor.predict(X_test)\n",
    "predict = scaler.inverse_transform(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c46845",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(real_price, color = \"blue\", label = \"Real Stock Price\")\n",
    "plt.plot(predict, color = \"red\", label = \"Predict Stock Price\")\n",
    "plt.title(\"Stock Price Prediction\")\n",
    "plt.xlabel(\"2012 - 2020 (Days)\")\n",
    "plt.ylabel(\"AAPL Stock Price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62cb6d1",
   "metadata": {},
   "source": [
    "## Second Analysis: Long Short-Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afe3e71",
   "metadata": {},
   "source": [
    "The next step in analyzing this data includes an LSTM model, which is to be run on the same individual stock and compare its prediction with the RNN mode. \n",
    "\n",
    "LSTM is based on Keras, where they become useful in analyzing a prediction based on a sequence due to storing of past data. This is crucial in prediction of the stock market due to its historical data, since this has an influence on the price of its future stock. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f812d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0df52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.compile(optimizer= \"adam\", loss = \"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa35f1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note: Only run this once, it takes a long time to run within local machine.\n",
    "\"\"\"\n",
    "regressor.fit(X_train, y_train, epochs = epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fefd831",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(real_price, color = \"blue\", label = \"Real Stock Price\")\n",
    "plt.plot(predict, color = \"red\", label = \"Predict Stock Price\")\n",
    "plt.title(\"Stock Price Prediction\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"AAPL Stock Price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414b228c",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In conclusion, it is determine that the LSTM model is a better predictor against the case. This is not an ideal solution to predict the stock market; however, with some experimentation and hyperparameter tuning, this could be a viable option. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
