{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b45f279",
   "metadata": {},
   "source": [
    "## Linear Regression and LSTM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bb5a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a06252c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done importing\n"
     ]
    }
   ],
   "source": [
    "# Import Statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "print(\"Done importing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9dc16ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load symbols_valid_meta to get reference Stocks and ETFs with full name\n",
    "# Change this to match your filepath name\n",
    "nomenclature = pd.read_csv('/Users/taylor/ICS-438/big-data-stock-analysis/Notebooks/Data/symbols_valid_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "364df7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When reading the .csv in pandas df, special characters are treated differently\n",
    "# Manually renamed the files so no files are run into\n",
    "nomenclature.at[162,'Symbol'] = 'AGM-A'\n",
    "nomenclature.at[1068,'Symbol'] = 'CARR#'\n",
    "nomenclature.at[7457,'Symbol'] = 'UTX#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed4aaf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock file count:  5884\n",
      "Etf file count:  2165\n"
     ]
    }
   ],
   "source": [
    "# Import statement\n",
    "import pathlib\n",
    "\n",
    "# Iterate through the number of stocks\n",
    "stock_count, etf_count = 0, 0\n",
    "for path in pathlib.Path('/Users/taylor/ICS-438/big-data-stock-analysis/Notebooks/Data/stocks').iterdir():\n",
    "    if path.is_file():\n",
    "        stock_count += 1\n",
    "print(\"Stock file count: \", stock_count)\n",
    "\n",
    "# Iterate through the number of etfs\n",
    "for path in pathlib.Path('/Users/taylor/ICS-438/big-data-stock-analysis/Notebooks/Data/etfs').iterdir():\n",
    "    if path.is_file():\n",
    "        etf_count += 1\n",
    "print(\"Etf file count: \", etf_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f1de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the files into one big list of dataframes and normalize dates according to pandas\n",
    "# Yahoo finance package dealt with pandas date normalization already\n",
    "\n",
    "\"\"\"\n",
    "Please note:\n",
    "In order to run this, it is important to change your $PATH to reflect where the actual files are downloaded\n",
    "\"\"\"\n",
    "\n",
    "stock_df_list = []\n",
    "etf_df_list = []\n",
    "\n",
    "for i in range(len(nomenclature)):\n",
    "    if nomenclature['ETF'][i] == 'Y':\n",
    "        etf_df_list.append(pd.read_csv('Notebooks/Data/stocks/' + nomenclature['Symbol'][i] +'.csv'))\n",
    "    else:\n",
    "        stock_df_list.append(pd.read_csv('Notebooks/Data/etfs/' + nomenclature['Symbol'][i] +'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40c22ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Separate stocks into 3 types and drop stocks with a history < 3 years, 2018 and younger\n",
    "Type 1: Longer than 25 years\n",
    "Type 2: 25 Years and Younger\n",
    "Type 3: After 2009\n",
    "We will only be using type 3 stocks, since we do not want to deal with market crashes\n",
    "and any other event that will affect the volatility\n",
    "\"\"\"\n",
    "\n",
    "stocks_relevant = [s for s in stock_df_list if s['Date'][0] < '2018-01-01']\n",
    "stocks_type_3 = [s for s in stocks_relevant if s['Date'][0] > '2009-12-31']\n",
    "stocks_type_2 = [s for s in stocks_relevant if s['Date'][0] > '1994-12-31']\n",
    "stocks_type_1 = [s for s in stocks_relevant if s['Date'][0] < '1994-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de5a6596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Cleaning, preprocessing drop NaN rows and change date to days after first\n",
    "for i in range(len(stocks_type_3)): \n",
    "    stocks_type_3[i].dropna(axis=0, how='any', inplace=True)\n",
    "    stocks_type_3[i]['Date'] = pd.to_datetime(stocks_type_3[i]['Date'])\n",
    "    stocks_type_3[i]['Date'] = (stocks_type_3[i]['Date'] - stocks_type_3[i]['Date'].min())  / np.timedelta64(1,'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4cf530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_reg_accuracy(list_stock_df):\n",
    "    lin_acc = []\n",
    "    for i in range(len(list_stock_df)):\n",
    "        temp = list_stock_df[i]\n",
    "        temp = (temp-temp.min())/(temp.max()-temp.min()) #Min-Max Scaling\n",
    "        X = temp.drop(['Open','High', 'Low','Close', 'Adj Close'], axis=1)\n",
    "        y = temp['Open']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
    "        regressor = LinearRegression()\n",
    "        regressor.fit(X_train, y_train)\n",
    "        lin_acc.append(regressor.score(X_test, y_test))\n",
    "    return lin_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c845473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = lin_reg_accuracy(stocks_type_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f70bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = filter(lambda x: x > 0.85, accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fef0640",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(list(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bcf8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage of stocks with an R^2 value of greater than 85% is', length / len(accuracies), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e333f53",
   "metadata": {},
   "source": [
    "The above determines that the percentage of stocks with an R^2 value of greater than 50% is approximately 0.067. This means that linear regressions are not viable tools to successfully predicts a stocks value. The results determine that there is only a small percentage of stocks that follow clear correlated linear trend over time, as expected during a clear economic expansion. The years that we have also chosen determine that no clear events that determine volatility could have affected these prices. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de4f82",
   "metadata": {},
   "source": [
    "## Time Series Prediction of Tesla Stock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e22436c",
   "metadata": {},
   "source": [
    "The first step to determining whether these deep learning models are unsuccessful is to apply the, to how they compare to each other. We will be doing this time series prediction on Apple stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e809d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d7d03b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get AAPL stock into df and cut time to 2014 - 2020\n",
    "aapl = pd.read_csv('Notebooks/Data/stocks/' + 'AAPL' +'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "102f831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl = aapl.loc[(aapl['Date'] >= '2012-01-01') & (aapl['Date'] <= '2020-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34876a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train test\n",
    "training_size = int(len(aapl)*0.80)\n",
    "data_len = len(aapl)\n",
    "\n",
    "train, test = aapl[0:training_size],aapl[training_size:data_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d2a9c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size -->  1609\n",
      "total length of data -->  2012\n",
      "Train length -->  1609\n",
      "Test length -->  403\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Size --> \", training_size)\n",
    "print(\"total length of data --> \", data_len)\n",
    "print(\"Train length --> \", len(train))\n",
    "print(\"Test length --> \", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a88307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinMax scale values\n",
    "train = train.loc[:, [\"Open\"]].values\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_scaled = scaler.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835137d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_len = len(train_scaled)\n",
    "X_train, y_train = [], []\n",
    "timesteps = 40\n",
    "\n",
    "for i in range(timesteps, end_len):\n",
    "    X_train.append(train_scaled[i - timesteps:i, 0])\n",
    "    y_train.append(train_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f216be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to reshape our data as RNN needs 3 dimensions\n",
    "#the size of data we have, the number of steps and the number of features\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afab0537",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553ab6b4",
   "metadata": {},
   "source": [
    "This is the creation of the model and a specification of the parameters. We will determine the hyperbolic tangent as an activation function and dimensionality of output space to be a total of 50 units. The parameter values do not contain any specific special features, but are mostly based around their default values and values in our examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d81fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "\n",
    "regressor.add(SimpleRNN(units = 50, activation = \"tanh\", return_sequences = True, input_shape = (X_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(SimpleRNN(units = 50, activation = \"tanh\", return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(SimpleRNN(units = 50, activation = \"tanh\", return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(SimpleRNN(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928edef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.compile(optimizer= \"adam\", loss = \"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d0f8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100 \n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759fd7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note: Only run this once, it takes a long time to run within local machine.\n",
    "\"\"\"\n",
    "regressor.fit(X_train, y_train, epochs = epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159da8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_price = test.loc[:, [\"Open\"]].values\n",
    "print(\"Real Price Shape --> \", real_price.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c754ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_total = pd.concat((aapl[\"Open\"], test[\"Open\"]), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(test) - timesteps:].values.reshape(-1,1)\n",
    "inputs = scaler.transform(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9277eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "\n",
    "for i in range(timesteps, real_price.shape[0]+timesteps):\n",
    "    X_test.append(inputs[i-timesteps:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "print(\"X_test shape --> \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a92e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "predict = regressor.predict(X_test)\n",
    "predict = scaler.inverse_transform(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e4b1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(real_price, color = \"blue\", label = \"Real Stock Price\")\n",
    "plt.plot(predict, color = \"red\", label = \"Predict Stock Price\")\n",
    "plt.title(\"Stock Price Prediction\")\n",
    "plt.xlabel(\"2012 - 2020 (Days)\")\n",
    "plt.ylabel(\"AAPL Stock Price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8146d0f0",
   "metadata": {},
   "source": [
    "## Long Short-Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5482a0b",
   "metadata": {},
   "source": [
    "The next step in analyzing this data includes an LSTM model, which is to be run on the same individual stock and compare its prediction with the RNN mode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e027ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd571343",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.compile(optimizer= \"adam\", loss = \"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a4745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note: Only run this once, it takes a long time to run within local machine.\n",
    "\"\"\"\n",
    "regressor.fit(X_train, y_train, epochs = epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cf566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(real_price, color = \"blue\", label = \"Real Stock Price\")\n",
    "plt.plot(predict, color = \"red\", label = \"Predict Stock Price\")\n",
    "plt.title(\"Stock Price Prediction\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"AAPL Stock Price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e018186",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In conclusion, it is determine that the LSTM model is a better predictor against the case. This is not an ideal solution to predict the stock market; however, with some experimentation and hyperparameter tuning, this could be a viable option. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
